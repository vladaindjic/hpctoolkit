\input texinfo  @c -*-texinfo-*-

@setfilename install.texi
@settitle Installing HPCToolkit with Spack

@ifhtml
@contents
@end ifhtml

@section Introduction

These notes describe how to build and install HPCToolkit and hpcviewer
and their prerequisites with Spack.  HPCToolkit proper (hpcrun,
hpcstruct and hpcprof) is used to measure and analyze an application's
performance and then produce a database for hpcviewer.  HPCToolkit is
supported on the following platforms.

@enumerate
@item
Linux (64-bit) on x86_64, big and little-endian powerpc (power7, 8 and
9) and ARM (aarch64).

@item
Cray XT/XE/XK/XC on x86_64 and Compute Node Linux.

@item
IBM Blue Gene/Q on ppc64.
@end enumerate

@noindent
We provide binary distributions for hpcviewer and hpctraceviewer on
Linux (x86_64 and powerpc), Windows and MacOS.  HPCToolkit databases are
platform-independent and it is common to run hpcrun on one machine and
then view the results on another machine.

We build HPCToolkit and its prerequisite libraries from source.
HPCToolkit has some 15-20 prerequisites and we now use spack to build
them.  It is possible to use spack to install all of hpctoolkit or
build just the prerequisites and then build hpctoolkit with the
traditional @code{configure ; make ; make install} method from
autotools.  Developers will probably want to run @code{configure} and
@code{make} manually, but both methods are supported.

Note: the old method of using hpctoolkit-externals to build the
prerequisite libraries is now superseded by spack.  Although externals
will continue to work for a while, we have stopped updating externals
and now add newer versions of packages only in spack.

These notes are written mostly from the view of using spack to build
hpctoolkit and its dependencies.  If you are a more experienced spack
user, especially if you want to use spack to build hpctoolkit plus
several other packages, then you will want to adapt these directions to
your own needs.

Spack documentation is available at:

@example
@uref{https://spack.readthedocs.io/en/latest/index.html}
@end example

@noindent
The current status of using Spack for HPCToolkit is at:

@example
@uref{http://hpctoolkit.org/spack-issues.html}
@end example

@c ------------------------------------------------------------

@section Prerequisites

Building HPCToolkit requires the following prerequisites.

@enumerate
@item
The GNU gcc and g++ compilers version 4.8 or later and preferably 5.x or
later.  On systems with older compilers, you can use spack to build a
later version of gcc.

@item
Basic build tools: make, ld, ar, objcopy, nm, etc, and shell utilities:
bash, sed, awk, grep, etc.  Most Linux systems have these tools, or else
you couldn't compile anything.

@item
Cmake version 3.4 or later, perl version 5.x, and python version 2.7 or
3.4 or later.  On systems that are missing these tools or have versions
that are too old, you can use spack to build a later version.

@item
Git and curl for downloading files.

@item
(optional) Environment (TCL) or LUA (Lmod) modules, if you want to make
HPCToolkit available as a module.  Again, spack can install these
packages if they are missing from your system.
@end enumerate

@noindent
Hpcviewer and hpctraceviewer require Java version 8.  On Linux, the
viewers also require GTK+ version 2.x.

@c ------------------------------------------------------------

@section Clone Spack and HPCToolkit

Spack is available via git clone from GitHub.  This includes the core
spack machinery and recipes for building more than 3,000 packages (and
growing).  You should also clone HPCToolkit for the
@code{packages.yaml} file which is used to configure the spack build.

@example
git clone https://github.com/spack/spack.git
git clone https://github.com/hpctoolkit/hpctoolkit.git
@end example

@noindent
After cloning, add the @code{spack/bin} directory to your PATH, or else
source the spack @code{setup-env} script.

@example
(bash)   .  /path/to/spack/share/spack/setup-env.sh
(csh)    setenv SPACK_ROOT /path/to/spack/root
         source $SPACK_ROOT/share/spack/setup-env.csh
@end example

@noindent
It suffices to add @code{spack/bin} to your PATH (or even symlink the
spack launch script).  Sourcing the @code{setup-env} script adds extra
support for modules built by spack.

@c ------------------------------------------------------------

@section Config.yaml

@code{config.yaml} is the top-level spack config file.  This specifies
the directory layout for installed files and the top-level spack
parameters.  There are two or three fields in this file that you should
set for your local system.

@enumerate
@item
@code{install_tree} -- by default, spack installs packages inside the
spack repository at @code{spack/opt/spack}.  If you want to use another
location, then set this.

@item
@code{module_roots} -- by default, spack installs module files inside
the spack repository at @code{spack/share/spack}.  If you want to use
another location, then set this.

@item
@code{build_jobs} -- by default, spack uses all available hardware
threads for parallel make.  For machines with many threads, this can
sometimes overwhelm the system and you should set this to a smaller
number.  (There is precedent.)
@end enumerate

@noindent
There are also parameters for the locations of the build directories,
the cache of downloaded tar files, etc, which you may wish to set.

The default @code{config.yaml} file is in the spack repository at
@code{spack/etc/spack/defaults}.  The simplest solution is to copy this
file one directory up and then edit the copy (don't edit the default
file directly).

@example
cd spack/etc/spack
cp defaults/config.yaml .
vi config.yaml
@end example

@noindent
Alternatively, you could put this file in a separate directory, outside
of the spack repository and then use @code{-C dir} on the spack command
line.  (The @code{-C} option goes before the spack command name.)

@example
spack -C dir install ...
@end example

@noindent
Note: if you put @code{config.yaml} in @code{spack/etc/spack}, then it
will apply to every spack command for that repository (and you won't
forget).  Putting it in a separate directory is more flexible because
you can support multiple configurations from the same repository.  But
then you must use @code{-C dir} with every spack command or else you
will get inconsistent results.

You can view the current configuration with @code{spack config}.

@example
spack [-C dir] config get config
@end example

@noindent
See the spack docs on `Configuration Files' and `Basic Settings'.

@example
@uref{https://spack.readthedocs.io/en/latest/configuration.html}
@uref{https://spack.readthedocs.io/en/latest/config_yaml.html}
@end example

@c ------------------------------------------------------------

@section Packages.yaml

The @code{packages.yaml} file specifies the versions and variants for
the packages that spack installs and serves as a common reference
point for HPCToolkit's prerequisites.  This file also specifies the
paths or modules for system build tools (cmake, python, etc) to avoid
rebuilding them.  Put this file in the same directory as
@code{config.yaml}.  A sample @code{packages.yaml} file is available
in the @code{spack} directory of the hpctoolkit repository.

There are two main sections to @code{packages.yaml}.  The first
specifies the versions and variants for hpctoolkit's prereqs.  By
default, spack will choose the latest version of each package (plus
any constraints from hpctoolkit's @code{package.py} file).  In most
cases, this will work, but not always.  If you need to specify a
different version or variant, then set this in @code{packages.yaml}.

Note: the versions and variants specified in hpctoolkit's
@code{package.py} file are hard constraints and should not be changed.
Variants in @code{packages.yaml} are preferences that may be modified
for your local system.  (But don't report a bug until you have first
tried the versions from @code{packages.yaml} that we supply.)

There are at least two packages with a variant that you may need to
change depending on your system.  But always check the current
@code{packages.yaml} file to see if any more have been added.

@enumerate
@item
@code{intel-tbb} -- for very old Intel or AMD systems that don't support
transactional memory, change @code{+tm} to @code{~tm}.  (This option has
no effect on non-x86 systems.)

@item
@code{libmonitor} -- on Blue Gene/Q, add @code{+bgq}.
@end enumerate

@noindent
The second section in @code{packages.yaml} specifies a path or module
for system build tools.  Building hpctoolkit's prerequisites requires
cmake 3.4 or later, perl 5.x and python 2.7 or 3.4 or later.  There are
three ways to satisfy these requirements: a system installed version
(eg, /usr), a pre-built module or build from scratch.

By default, spack will rebuild these from scratch, even if your local
version is perfectly fine.  If you already have an installed version
and prefer to use that instead, then you can specify this in
@code{packages.yaml}.  Note that these are only build tools.
Hpctoolkit does not link with any of their libraries.

For example, this entry says that cmake 3.7.2 is available from module
@code{CMake/3.7.2} and that spack should use this instead of building
its own copy.

@example
cmake:
  modules:
    cmake@@3.7.2:  CMake/3.7.2
  buildable: False
@end example

@noindent
This example says that perl v5.16.3 is installed at
@code{/usr/bin/perl}.  Note that the @code{paths:} entry is the parent
directory of @code{bin}, not the bin directory itself (similar to
prefix).

@example
perl:
  paths:
    perl@@5.16.3:  /usr
  buildable: False
@end example

@noindent
See the spack docs on 'Build Customization' and 'Specs and
Dependencies'.

@example
@uref{https://spack.readthedocs.io/en/latest/build_settings.html}
@uref{https://spack.readthedocs.io/en/latest/basic_usage.html#specs-dependencies}
@end example

@c ------------------------------------------------------------

@section Compilers and compilers.yaml

Building HPCToolkit requires GNU gcc/g++ at a minimum version 4.8 and
preferably 5.x or later.  By default, spack uses the latest available
version of gcc, but you can specify a different compiler, if one is
available.

Spack uses a separate file, @code{compilers.yaml} to store information
about available compilers.  This file is normally in your home directory
at @code{~/.spack/platform} where `platform' is normally `linux' (or
else `cray' or `bgq').

The first time you use spack, or after adding a new compiler, you should
run @code{spack compiler find} to have spack search your system for
available compilers.  If a compiler is provided as a module, then you
should load the module before running @code{find}.  Normally, you only
need to run @code{find} once, unless you want to add or delete a
compiler.  You can also run @code{spack compiler list} and @code{spack
compiler info} to see what compilers spack knows about.

For example, on one power8 system running RedHat 7.3, /usr/bin/gcc is
version 4.8.5, but gcc 6.4.0 is available as module @code{GCC/6.4.0}.

@example
module load GCC/6.4.0

spack compiler find
==> Added 2 new compilers to /home/krentel/.spack/linux/compilers.yaml
    gcc@@6.4.0  gcc@@4.8.5
==> Compilers are defined in the following files:
    /home/krentel/.spack/linux/compilers.yaml

spack compiler list
==> Available compilers
-- gcc rhel7-ppc64le --------------------------------------------
gcc@@6.4.0  gcc@@4.8.5

spack compiler info gcc@@6.4
gcc@@6.4.0:
    paths:
        cc = /opt/apps/software/Core/GCCcore/6.4.0/bin/gcc
        cxx = /opt/apps/software/Core/GCCcore/6.4.0/bin/g++
        f77 = /opt/apps/software/Core/GCCcore/6.4.0/bin/gfortran
        fc = /opt/apps/software/Core/GCCcore/6.4.0/bin/gfortran
    modules  = ['GCC/6.4.0']
    operating system  = rhel7
@end example

@noindent
Note: for compilers from modules, spack does not fill in the
@code{modules:} field in the @code{compilers.yaml} file.  You need to
do this manually.  In the above example, after running @code{find}, I
edited @code{compilers.yaml} to add @code{GCC/6.4.0} to the
@code{modules:} field as below.  This is important to how spack
manipulates the build environment.

@example
- compiler:
    modules: [GCC/6.4.0]
    operating_system: rhel7
    spec: gcc@@6.4.0
    ...
@end example

@noindent
Spack uses @code{%} syntax to specify the build compiler and @code{@@}
syntax to specify the version.  For example, suppose you had gcc
versions 7.3.1, 6.4.0 and 5.4.0 available and you wanted to use 6.4.0.
You could write this as:

@example
spack install package %gcc@@6.4.0
@end example

@noindent
See the spack docs on `Compiler Configuration'.

@example
@uref{https://spack.readthedocs.io/en/latest/getting_started.html#compiler-configuration}
@end example

@c ------------------------------------------------------------

@section Spack Install

First, make sure that you have your @code{config.yaml},
@code{packages.yaml} and @code{compilers.yaml} files in place and
edited for your system.  You can see how spack will build hpctoolkit
with @code{spack spec} and @code{spack graph}.

@example
spack spec hpctoolkit
spack graph hpctoolkit
@end example

@noindent
Then, there are two ways to install hpctoolkit.  The `one button' method
uses spack to install everything.

@example
spack install hpctoolkit
@end example

@noindent
Alternatively, especially for developers, you can use spack to install
hpctoolkit's dependencies and then build hpctoolkit with the traditional
@code{configure ; make ; make install} method.  Of course, if you
already used the one-button method, then the spack install tree also
contains all of hpctoolkit's prereqs.

@example
spack install --only dependencies hpctoolkit
@end example

@noindent
Then, run hpctoolkit configure with @code{--with-spack} instead of
@code{--with-externals}.  The @code{--with-spack} option passes the
prerequisite paths to hpctoolkit in place of all of the individual
@code{--with-pkg} options (as did externals).

Spack installs its packages in subdirectories of @code{install_tree}
named by architecture (platform, OS, machine type) and compiler
(family, version).  The argument to @code{--with-spack} should be the
directory containing all of the individual install directories
(normally two directories down from the install root).  For example,
on my Fedora 26 build machine, I would use:

@example
configure  \
   --prefix=/path/to/hpctoolkit/install/prefix  \
   --with-spack=/path/to/spack/install_tree/linux-fedora26-x86_64/gcc-7.3.1  \
   ...
make -j <num>
make install
@end example

@noindent
Note: if your spack install tree has multiple versions or variants for
the same package, then @code{--with-spack} will select the most recent
one by directory time stamp (and issue a warning).  If this is not
what you want, then you will need to specify the correct version with
a @code{--with-pkg} option.

@c ------------------------------------------------------------

@section Advanced Options

@subsection MPI

HPCToolkit always supports profiling MPI applications.  For
hpctoolkit, the spack variant @code{+mpi} is for building hpcprof-mpi,
the MPI version of hpcprof.  If you want to build hpcprof-mpi, then
you need to supply an installation of MPI.

Normally, for systems with compute nodes, you should use an existing
MPI module that was built for the correct interconnect for your system
and add this to @code{packages.yaml}.  The MPI module should be built
with the same version of GNU gcc/g++ used to build hpctoolkit (to keep
the C++ libraries in sync).

@subsection PAPI vs Perfmon

HPCToolkit can access the Hardware Performance Counters with either
PAPI or Perfmon (libpfm4).  By default, the hpctoolkit package uses
perfmon.  If you want to use PAPI instead, then build hpctoolkit with
@code{+papi}.  However, you can't use both due to a potential conflict
in their header files.

PAPI runs on top of the perfmon library, but PAPI uses its own,
internal copy of perfmon.  Prior to version 5.6.0, PAPI did not
install the perfmon header files, so it was impossible to access the
perfmon events through PAPI.

However, starting with version 5.6.0, PAPI now installs both the
perfmon library and its header files.  Hpctoolkit configure will
automatically detect this, so if you build hpctoolkit with a recent
enough version of PAPI, then both the PAPI and perfmon interfaces will
be available.

@c ------------------------------------------------------------

@section Platform Specific Notes

@subsection Blue Gene

Blue Gene systems are being phased out, without a next generation
replacement, but are still supported by hpctoolkit (for now).  Blue
Gene normally comes with a Red Hat Enterprise Linux (RHEL) 6.x front
end and the GNU gcc/g++ 4.4 compilers with are too old to support the
latest version of hpctoolkit.

Spack supports two architecture types on Blue Gene.  The front-end arch
is @code{bgq-rhel6-ppc64} and the back-end arch is @code{bgq-cnk-ppc64}.
Normally, it would matter whether we built for the front end or back
end.  But for the GNU compilers on Blue Gene, both compilers are
/usr/bin/gcc.  So, we just build for the default back end.

There are two ways to build hpctoolkit for Blue Gene, depending on the
version of the compiler and Dyninst.  The simple method uses the default
GCC 4.4 compiler and Dyninst 9.3.2.  Edit these two entries in the
@code{packages.yaml} file.

@enumerate
@item
Set the dyninst version to @code{9.3.2}.

@item
Add @code{+bgq} to the libmonitor variants.
@end enumerate

@noindent
Then, build hpctoolkit with @code{+bgq} turned on.  The @code{+bgq}
variant adds MPI and hpcprof-mpi and supersedes the @code{+mpi}
variant.

@example
spack install hpctoolkit +bgq
@end example

@noindent
The advanced method involves building a new compiler (gcc 4.8 or 4.9)
but allows using Dyninst 10.x.  This method requires TCL or Lmod
modules and an MPI C++ compiler built for a compatible version of g++.
Mira and vesta at ANL have softenv modules for +mpiwrapper-gcc and
+bgqtoolchain-gcc484 but don't provide TCL or Lmod modules.

First, use spack to build a new compiler.  Dyninst 10.x requires
gcc@w{ }4.8 or later, but libmonitor requires the true back-end
@code{powerpc64-bgq-linux-gcc} compiler which is version 4.4.  We
settle on gcc 4.8.5 as a compromise between these two constraints.
Edit @code{config.yaml} to set @code{module_roots} to a directory in
which to install the modules and then build gcc.

@example
spack install gcc @@4.8.5
@end example

@noindent
Assuming you have modules installed, then load the new gcc module and
rerun @code{spack compiler find}.  This should add the new compiler to
your @code{compilers.yaml} file (twice, for front and back end).  For
example, on vulcan at LLNL,

@example
module use /path/to/modules/bgq-cnk-ppc64
module load gcc-4.8.5-gcc-4.4.7-nzvjwva
spack compiler find
==> Added 2 new compilers to /g/g21/krentel1/.spack/bgq/compilers.yaml
    gcc@@4.8.5  gcc@@4.8.5
@end example

@noindent
Note: after running @code{spack compiler find}, you still need to add
the modules field to the compiler entry in @code{compilers.yaml} as in
the section on Compilers.

Note: in the above example, we used gcc 4.4.7 to build gcc 4.8.5 (so
the gcc-4.8.5 package is in the gcc-4.4.7 directory).  You could then
use gcc 4.8.5 to rebuild 4.8.5, if you like, but this is not
necessary.

Finally, use the new compiler to build hpctoolkit with the new compiler.
If you have modified the dyninst entry in @code{packages.yaml}, then
reset the dyninst version to 10.1.0 (or later).

@example
spack install hpctoolkit +bgq %gcc@@4.8.5
@end example

@noindent
If you don't have modules installed, then use @code{spack bootstrap}
to build the environment-modules package.  Then, source the bash or
csh script in the @code{Modules/init} directory to add the
@code{module} function to your environment.  For example,

@example
spack bootstrap
cd /path/to/environment-modules-4.2.4-rwtvlanuss35fxd3xuyldbfopt2m4ecs/init
(bash)  . ./bash
(csh)   source ./csh
@end example

@noindent
Alternatively, you could try adding the module environment variables
(PATH and LD_LIBRARY_PATH) manually, but then you may have to run
spack install with @code{--dirty}.  The @code{--dirty} option tells
spack not to erase LD_LIBRARY_PATH while building packages.

@example
spack install --dirty hpctoolkit +bgq %gcc@@4.8.5
@end example

@noindent
For developers, if you are building hpctoolkit directly (outside of
spack) but using spack prerequisites, then use a configure line
similar to the following.

@example
configure  \
    --prefix=/path/to/install/prefix  \
    --with-spack=/path/to/bgq-cnk-ppc64/gcc-4.8.5  \
    --enable-bgq  \
    --enable-all-static  \
    MPICXX=mpicxx
@end example

@c ------------------------------------------------------------

@subsection Cray

Cray systems, like Blue Gene, have separate front and back-end
architecture types.  For example, on theta at ANL, the front-end arch
is @code{cray-sles12-x86_64} (SuSE Linux version 12 for x86_64) and
the back-end is @code{cray-cnl6-mic_knl} (Compute Node Linux for KNL).

Hpctoolkit needs to be built with the GNU Programming Environment and
the front-end x86_64 compilers, plus the @code{CC} MPI C++ wrapper.
Switch to the @code{PrgEnv-gnu} module and unload the darshan module.
Darshan is a profiling tool that monitors an application's use of I/O,
but it conflicts with hpctoolkit.

@example
module swap PrgEnv-intel PrgEnv-gnu
module unload darshan
@end example

@noindent
By default, spack probably does not recognize the gcc compiler modules
as front-end compilers.  You have to tell spack to add them
explicitly.  Check that the latest gcc module is loaded (it probably
is from @code{PrgEnv-gnu}) and run @code{spack compiler find} with the
path to the compiler (one directory up from @code{bin}).  For example,
on theta at ANL,

@example
module load gcc/7.3.0
spack compiler find /opt/gcc/7.3.0
spack compiler list
==> Available compilers
-- gcc cnl6-any -------------------------------------------------
gcc@@7.3.0  gcc@@7.2.0  gcc@@7.1.0  gcc@@6.3.0  gcc@@6.1.0  gcc@@5.3.0
gcc@@4.9.3

-- gcc sles12-x86_64 --------------------------------------------
gcc@@7.3.0  gcc@@4.8
@end example

@noindent
Normally, spack does not fill in the @code{modules:} field for the new
compiler, you have to add that manually.  And although we mostly use
the front-end environment, we also need the @code{CC} wrapper to be
the back-end MPI compiler.

Spack does not support using both front-end and back-end compilers in
the same build.  But there are two workarounds for Cray.  One option is
to load the @code{cray-mpich} module and run @code{spack install} with
option @code{--dirty}.  A better way is to add @code{cray-mpich} to the
list of modules for gcc in @code{compilers.yaml}.  Edit the front-end
gcc entry (operating system sles12 and target x86_64) to add the
following modules (your versions may differ).

@example
- compiler:
    modules:
    - PrgEnv-gnu/6.0.4
    - gcc/7.3.0
    - cray-mpich/7.7.3
    operating_system: sles12
    paths:
      cc: /opt/gcc/7.3.0/bin/gcc
      cxx: /opt/gcc/7.3.0/bin/g++
      f77: /opt/gcc/7.3.0/bin/gfortran
      fc: /opt/gcc/7.3.0/bin/gfortran
    spec: gcc@@7.3.0
    target: x86_64
@end example

@noindent
This tells spack to load the above modules when using the gcc 7.3.0
compiler.  With the cray-mpich module loaded, the @code{CC} wrapper
becomes an MPI C++ compiler, which is what hpctoolkit needs.

Next, review your @code{packages.yaml} file.  On Cray systems with
Xeon Phi back-end nodes (KNL, KNH, etc), add @code{~tm} to intel-tbb
to disable transactional memory.

Finally, build hpctoolkit with the front-end arch type
(cray-sles12-x86_64) and option @code{+cray}.  Normally, you can use OS
type @code{fe} (front-end) in place of @code{sles12}.  As with Blue
Gene, the @code{+cray} option adds MPI and hpcprof-mpi and supersedes
the @code{+mpi} variant.

@example
spack install hpctoolkit +cray arch=cray-fe-x86_64
@end example

@noindent
For developers, if you are building hpctoolkit directly (outside of
spack) but using spack prerequisites, then use a configure line
similar to the following.

@example
configure  \
    --prefix=/path/to/install/prefix  \
    --with-spack=/path/to/cray-sles12-x86_64/gcc-7.3.0  \
    --enable-all-static  \
    MPICXX=CC
@end example

@c ------------------------------------------------------------

@section Hpcviewer and Hpctraceviewer

We provide binary distributions for hpcviewer and hpctraceviewer on
Linux (x86_64 and powerpc), Windows and MacOS.  HPCToolkit databases are
platform-independent and it is common to run hpcrun on one machine and
then view the results on another machine.

All versions of the viewers require Java version 8 (not 9 or later).
The Linux versions also require GTK+ version 2.x.

@subsection Spack Install

The spack install is available on Linux x86_64, big-endian power7
(ppc64) and little-endian power8 and 9 (ppc64le).  This installs both
hpcviewer and hpctraceviewer and includes the Java 8 prerequisite.

On x86_64, use the following command.  Hpcviewer requires jdk 1.8, but
the latest 1.8 version, 1.8.0_202 does not download properly due to
licensing issues, however 1.8.0_141-b15 seems to work.

@example
spack install hpcviewer ^jdk@@1.8.0_141-b15
@end example

@noindent
On powerpc (big and little-endian), use the IBM version of Java.

@example
spack install hpcviewer ^ibm-java
@end example

@subsection Manual Install

Binary distributions of the viewers for all supported platforms are
available at:

@example
@uref{http://hpctoolkit.org/download/hpcviewer}
@end example

@noindent
On Linux, download the @code{linux.gtk} versions of hpcviewer and
hpctraceviewer, unpack the tar files and run the install scripts (for
both viewers) with the path to the desired install prefix.

@example
./install /path/to/install/directory
@end example

@noindent
On Windows and MacOS, download the @code{win32} or @code{macosx.cocoa}
versions and unpack the zip files in the desired directory.  Due to
Apple's security precautions, on MacOS, you will need to use curl or
wget instead of a web browser.

@c ------------------------------------------------------------

@section Common Problems

@subsection Unable to fetch tar file

Spack is somewhat fragile for how it downloads tar files and will
often fail for transitory network problems.  This is especially true
for packages with many dependencies.  For example:

@example
==> Installing m4
==> Searching for binary cache of m4
==> No binary for m4 found: installing from source
curl: (6) Could not resolve host: ftp.wayne.edu; Name or service not known
==> Fetching https://ftpmirror.gnu.org/m4/m4-1.4.18.tar.gz
==> Fetching from https://ftpmirror.gnu.org/m4/m4-1.4.18.tar.gz failed.
==> Error: FetchError: All fetchers failed for m4-1.4.18-vorbvkcjfac43b7vuswsvnm6xe7w7or5
@end example

@noindent
There are two workarounds.  First, assuming the problem is temporary,
simply wait 10 minutes or an hour and try again.

Second, you could set up a spack mirror.  A mirror allows you to
download a tar file ahead of time and put it in a directory where
spack can find it without having to fetch it over a network.  A mirror
is also useful for files with license issues (eg, jdk 1.8.0_202 as
above), or on a secure machine without direct access to the internet.
See:

@example
@uref{https://spack.readthedocs.io/en/latest/mirrors.html}
@end example

@subsection New releases break the build

Normally, HPCToolkit should build and work correctly with the latest
version for all of its dependencies.  But sometimes a new release will
change something and break the build.  This has happened a couple times
where a new release of Boost has broken the build for Dyninst.  Or,
maybe the latest version of gcc/g++ disallows some usage and breaks the
build.

The solution is to use @code{packages.yaml} to specify an earlier
version until the rest of the code adapts to the change.

@bye
